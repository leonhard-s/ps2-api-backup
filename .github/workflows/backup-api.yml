# This workflow will run the "tools/scraper.py" script once a day, while also
# committing any changes to the repository.

name: Create API Backup

on:
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch: {}

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install --upgrade --user -r tools/requirements.txt
      - name: Configure git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
      - name: Run scraper
        env:
          SERVICE_ID: ${{secrets.REPO_SERVICE_ID}}
        run: |
          python tools/scraper.py
      - name: Cancel workflow on error
        if: ${{ failure() }}
        uses: styfle/cancel-workflow-action@0.10.0
        with:
          access_token: ${{ github.token }}
      - name: Filter changes
        run: |
          git add data
          git stash save --keep-index --include-untracked
      - name: Commit and push relevant changes
        continue-on-error: true
        run: |
          git commit -m "Automatic Scraper Update"
          git push origin main
